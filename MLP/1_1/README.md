Mulitlayer Perceptron

Goal: 
    a. Build a Multilayer Perceptron (MLP) and train it on the MNIST hand-written digit dataset.
    b. Compare three setups by plotting the losses against the training time.

Model: 
    input: 784 units
    hidden layer 1 : 250 units
    hidden layer 2 : 250 units
    output : 10 units

Initialize weights in three methods:
    a. initialize to be zeros
    b. initialize to be Normal distribution
    c. initialize to be Glorot distribution
    
Result:

    






